{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CartAndPole.QLearningTabular.Agent import Agent\n",
    "from CartAndPole.QLearningTabular.DoubleQLearningPolicy import DoubleQLearningPolicy as Policy\n",
    "from Core.Utility.EpsilonGreedyStrategy import EpsilonGreedyStrategy\n",
    "from CartAndPole.QLearningTabular.EnvironmentManager import EnvironmentManager\n",
    "from IPython.display import clear_output, display\n",
    "from itertools import count\n",
    "from Core.Utility.Helper import Helper\n",
    "from Core.Utility.DecayingLearningRate import DecayingLearningRate\n",
    "from Core.Utility.UCB import UCB \n",
    "import numpy as np\n",
    "\n",
    "epsilon_start = 1\n",
    "epsilon_end = 0.01\n",
    "epsilon_decay = 0.001\n",
    "\n",
    "initial_lr = 0.01\n",
    "decay_rate = 0.000002\n",
    "min_lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'episode 155000'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 28\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m count():\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(stateHasChanged):\n\u001b[1;32m---> 28\u001b[0m         currentState \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetState\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;66;03m# select = 1 if np.random.random() >= .5 else 0\u001b[39;00m\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.5\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\ICT SW UNIT\\MachineLearningCode\\ML\\CartAndPole\\QLearningTabular\\Agent.py:34\u001b[0m, in \u001b[0;36mAgent.getState\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m     32\u001b[0m cartVelocity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdigitize(cartVelocity, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcartVelocitySpace[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     33\u001b[0m poleAngle \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdigitize(poleAngle, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoleAngleSpace[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 34\u001b[0m poleAngleVelocity \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdigitize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoleAngleVelocity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoleAngleVelocitySpace\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (cartPosition, cartVelocity, poleAngle, poleAngleVelocity)\n",
      "File \u001b[1;32mc:\\Users\\ICT SW UNIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\function_base.py:5733\u001b[0m, in \u001b[0;36mdigitize\u001b[1;34m(x, bins, right)\u001b[0m\n\u001b[0;32m   5731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;241m-\u001b[39m _nx\u001b[38;5;241m.\u001b[39msearchsorted(bins[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], x, side\u001b[38;5;241m=\u001b[39mside)\n\u001b[0;32m   5732\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 5733\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearchsorted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mside\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ICT SW UNIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1400\u001b[0m, in \u001b[0;36msearchsorted\u001b[1;34m(a, v, side, sorter)\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_searchsorted_dispatcher)\n\u001b[0;32m   1333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearchsorted\u001b[39m(a, v, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, sorter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1334\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;124;03m    Find indices where elements should be inserted to maintain order.\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1398\u001b[0m \n\u001b[0;32m   1399\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msearchsorted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mside\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msorter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ICT SW UNIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "agent = Agent()\n",
    "stateSpace = agent.initializeState()\n",
    "epsilonGreedy = EpsilonGreedyStrategy(epsilon_start, epsilon_end, epsilon_decay)\n",
    "decayingLearningRate = DecayingLearningRate(initial_lr, decay_rate, min_lr)\n",
    "environment = EnvironmentManager('CartPole-v1')\n",
    "policy1 = Policy() \n",
    "policy1.initializePolicy(stateSpace, environment.actionSpace.n)\n",
    "\n",
    "policy2 = Policy() \n",
    "policy2.initializePolicy(stateSpace, environment.actionSpace.n)\n",
    "ucb = UCB(environment.actionSpace.n, len(stateSpace), .1)\n",
    "\n",
    "\n",
    "\n",
    "numberOfEpisodes = 500000\n",
    "score = [0]\n",
    "scoreCounter = 0\n",
    "stateDict = dict(zip(stateSpace, range(len(stateSpace))))\n",
    "for episode in range(numberOfEpisodes):\n",
    "    stateHasChanged = True\n",
    "        \n",
    "    for step in count():\n",
    "        \n",
    "        \n",
    "      \n",
    "        if(stateHasChanged):\n",
    "            \n",
    "            currentState = agent.getState(environment.observation)\n",
    "            # select = 1 if np.random.random() >= .5 else 0\n",
    "            if(np.random.random() >= .5):\n",
    "                selectionPolicy = policy1\n",
    "                updatePolicy = policy2\n",
    "            else:\n",
    "                selectionPolicy = policy2\n",
    "                updatePolicy = policy1\n",
    "            \n",
    "            action = epsilonGreedy.chooseAction(currentState, selectionPolicy, episode)\n",
    "            # action = policy.getRandomAction()\n",
    "            # action = policy.getMaxAction(currentState)\n",
    "            # action = ucb.chooseAction(stateDict[currentState])\n",
    "            reward, terminated = environment.step(action)\n",
    "            # ucb.update(stateDict[currentState], action, reward)\n",
    "            nextState = agent.getState(environment.observation)\n",
    "         \n",
    "           \n",
    "            # policy.setTrainingRate(decayingLearningRate.getLearningRate(episode))\n",
    "            if(not terminated):\n",
    "                # policy.setTrainingRate(0.001)\n",
    "                selectionPolicy.train(currentState, nextState, reward, action, updatePolicy)\n",
    "            \n",
    "            stateHasChanged = currentState != nextState\n",
    "            \n",
    "        else:\n",
    "            reward, terminated = environment.step(action)\n",
    "            nextState = agent.getState(environment.observation)\n",
    "            stateHasChanged = currentState != nextState\n",
    "          \n",
    "        \n",
    "        scoreCounter += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        if terminated:\n",
    "            reward = -10\n",
    "            selectionPolicy.train(currentState, nextState, reward, action, updatePolicy)\n",
    "            \n",
    "            score.append(scoreCounter)\n",
    "            scoreCounter = 0\n",
    "            environment.reset()\n",
    "            \n",
    "            if(episode % 200 == 0):\n",
    "                clear_output(wait=True)\n",
    "                display(f\"episode {episode}\")\n",
    "                display(int(Helper.getMovingAverage3(300, score)))\n",
    "                # utility.plot(300 ,score)\n",
    "            \n",
    "            break\n",
    "        \n",
    "       \n",
    "            \n",
    "            \n",
    "environment.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = EnvironmentManager('CartPole-v1', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfEpisodes = 15\n",
    "\n",
    "for episode in range(numberOfEpisodes):\n",
    "        \n",
    "    for step in count():\n",
    "        clear_output(wait=True)\n",
    "        # display(f\"step {episode}\")\n",
    "        currentState = agent.getState(environment.observation)\n",
    "        \n",
    "        action = policy1.getMaxAction(currentState)\n",
    "        # action = policy.getRandomAction()\n",
    "        reward, terminated = environment.step(action)\n",
    "        nextState = agent.getState(environment.observation)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if terminated:\n",
    "            environment.reset()\n",
    "            break\n",
    "            \n",
    "environment.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = []\n",
    "for i, j in policy1.Q.items():\n",
    "    if(max(j) > 0):\n",
    "        s.append(f'{i} \\t {j}')\n",
    "        \n",
    "print(len(s))\n",
    "\n",
    "s\n",
    "    \n",
    "\n",
    "\n",
    "# import importlib\n",
    "# ag = importlib.import_module(\"Utility\")\n",
    "# ag = importlib.reload(ag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "state_low = env.observation_space.low\n",
    "state_high = env.observation_space.high\n",
    "\n",
    "\n",
    "n_bins = (4, 4, 4, 4)\n",
    "\n",
    "tiler = gym.spaces.Box(low=state_low, high=state_high, dtype=np.float32)\n",
    "    \n",
    "print(tiler)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
